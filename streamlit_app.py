import os
import pickle
from typing import Dict, List, Tuple
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# ================================
# Paths
# ================================
APP_DIR = Path(__file__).parent.resolve()
FIRST_CSV   = APP_DIR / "first.csv"
SECOND_CSV  = APP_DIR / "second.csv"
MODEL_PKL   = APP_DIR / "model.pkl"

# ================================
# OTT ê·¸ë£¹ ì„¤ëª… (íˆ´íŒì— ì‚¬ìš©)
# ================================
MAJOR_APPS = [
    "Disney+ (ë””ì¦ˆë‹ˆ+)",
    "ì¿ íŒ¡í”Œë ˆì´",
    "Wavve(ì›¨ì´ë¸Œ)",
    "TVING",
    "Netflix(ë„·í”Œë¦­ìŠ¤)",
]
MINOR_APPS = [
    "ì•„í”„ë¦¬ì¹´TV (AfreecaTV)",
    "Twitch: ê²Œì„ ìƒë°©ì†¡",
    "U+ëª¨ë°”ì¼tv",
    "ì™“ì± ",
    "SBS - ì˜¨ì—ì–´/VOD/ë°©ì²­",
    "KBS+",
    "NAVER NOW",
    "MBC",
    "ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆì˜¨ (SERIES ON)",
]
MAJOR_HELP = "ë©”ì´ì € OTT ì˜ˆì‹œ:\n- " + "\n- ".join(MAJOR_APPS)
MINOR_HELP = "ë§ˆì´ë„ˆ OTT ì˜ˆì‹œ:\n- " + "\n- ".join(MINOR_APPS)

# ================================
# Genre map
# ================================
GENRE_MAP = {
    1: "ë²„ë¼ì´ì–´í‹°/ì˜ˆëŠ¥",
    2: "ë“œë¼ë§ˆ",
    3: "ë‰´ìŠ¤",
    4: "ìŠ¤í¬ì¸ ",
    5: "ì·¨ë¯¸/ë ˆì €",
    6: "ìŒì•…",
    7: "êµìœ¡",
    8: "ì‹œì‚¬/ë‹¤í",
    9: "êµì–‘/ì •ë³´",
    10: "í™ˆì‡¼í•‘",
    11: "ì„±ì¸",
    997: "ê¸°íƒ€"
}
GENRE_LABEL_TO_CODE = {v: k for k, v in GENRE_MAP.items()}

# ================================
# MBTI ë³„ì¹­/ì„¤ëª…/ë§¤í•‘
# ================================
TYPE_ALIAS = {"ESFJ": "ENGAGED", "ESTJ": "PLANNED", "INTP": "TARGETED", "INFP": "JOYFUL"}
ALIAS_TO_TYPE = {
    "ENGAGED": "ESFJ", "STIMULATING": "ESFJ", "FRAGMENTED": "ESFJ",
    "PLANNED": "ESTJ", "NECESSITYFOCUSED": "ESTJ", "NECCESITYFOCUSED": "ESTJ",
    "TARGETED": "INTP",
    "JOYFUL": "INFP", "IDLE": "INFP",
    "ESFJ": "ESFJ", "ESTJ": "ESTJ", "INTP": "INTP", "INFP": "INFP",
}
DEFAULT_CLUSTER_TO_TYPE = {0: "ESFJ", 1: "ESTJ", 2: "INTP", 3: "INFP"}

DIM_DESC = {
    "E": "ì™¸í–¥(E): OTT ì‚¬ìš©ëŸ‰ì´ ë§ê³  ë‹¤ì–‘í•œ ì•±ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•©ë‹ˆë‹¤.",
    "I": "ë‚´í–¥(I): OTT ì‚¬ìš©ëŸ‰ì´ ì ê³  í˜¼ì ë³´ëŠ” ì„ íƒì Â·ì¡°ìš©í•œ ì´ìš©ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
    "S": "ê°ê°(S): ëª¨ë°”ì¼ ì•± ì¤‘ì‹¬ìœ¼ë¡œ ì¼ìƒ ì†ì— ìì—°ìŠ¤ëŸ½ê²Œ OTTë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
    "N": "ì§ê´€(N): ì—”í„°í…Œì¸ë¨¼íŠ¸/ë¯¸ë””ì–´ ë°©ì‹ìœ¼ë¡œ í˜¸ê¸°ì‹¬ì— ë”°ë¼ í­ë„“ê²Œ íƒìƒ‰í•©ë‹ˆë‹¤.",
    "T": "ì‚¬ê³ (T): ì‹¤ìš©ì„±ê³¼ í•„ìš”ì„±ì„ ì¤‘ì‹œí•˜ë©° íš¨ìœ¨ì ìœ¼ë¡œ ì½˜í…ì¸ ë¥¼ ê³ ë¦…ë‹ˆë‹¤.",
    "F": "ê°ì •(F): ì¦ê±°ì›€Â·ê³µê°ì„ ì¤‘ì‹œí•˜ë©° ê°ì •ì  ë§Œì¡±ì„ ìœ„í•´ ì‹œì²­í•©ë‹ˆë‹¤.",
    "J": "íŒë‹¨(J): ìê¸°ê´€ë¦¬ì™€ ê³„íšì„ ì„¸ì›Œ ì‹œì²­ íŒ¨í„´ì„ ê¾¸ì¤€íˆ ìœ ì§€í•©ë‹ˆë‹¤.",
    "P": "ì¸ì‹(P): ììœ Â·ì¦‰í¥ì ìœ¼ë¡œ ìƒí™©ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì‹œì²­í•©ë‹ˆë‹¤.",
}
SUMMARY_LINE = {
    "ESFJ": "ì™¸í–¥(E)+ê°ê°(S)+ê°ì •(F)+ê³„íší˜•(J) ì¡°í•©ìœ¼ë¡œ, ë§ì´ ì¦ê¸°ë˜ ì§ˆì„œ ìˆê²Œ ì‚¬ìš©í•˜ëŠ” íƒ€ì…ì…ë‹ˆë‹¤.",
    "ESTJ": "ì™¸í–¥(E)+ê°ê°(S)+ì‚¬ê³ (T)+ê³„íší˜•(J) ì¡°í•©ìœ¼ë¡œ, ëª©ì ê³¼ íš¨ìœ¨ ì¤‘ì‹¬ì˜ ì²´ê³„ì  ì‚¬ìš©ìì…ë‹ˆë‹¤.",
    "INTP": "ë‚´í–¥(I)+ì§ê´€(N)+ì‚¬ê³ (T)+ì¸ì‹í˜•(P) ì¡°í•©ìœ¼ë¡œ, ì ì€ ì–‘ì„ ì„ íƒÂ·ì§‘ì¤‘í•´ ê¹Šê²Œ íŒŒëŠ” íƒêµ¬í˜• ì‚¬ìš©ìì…ë‹ˆë‹¤.",
    "INFP": "ë‚´í–¥(I)+ì§ê´€(N)+ê°ì •(F)+ì¸ì‹í˜•(P) ì¡°í•©ìœ¼ë¡œ, ê°ì • ì´ì…ê³¼ íœ´ì‹ì„ ìœ„í•´ ììœ ë¡­ê²Œ ì‹œì²­í•˜ëŠ” ì‚¬ìš©ìì…ë‹ˆë‹¤.",
}

# ---------- ê³µí†µ ìœ í‹¸ ----------
def _norm_str(s: str) -> str:
    return "".join(ch for ch in str(s).upper() if ch.isalnum())

def mbti_letters(label: str) -> str:
    s = "".join(ch for ch in str(label).upper() if ch.isalpha())
    if len(s) >= 4:
        four = s[:4]
        ok = (four[0] in "EI") and (four[1] in "SN") and (four[2] in "TF") and (four[3] in "JP")
        return four if ok else s[:4]
    return s

def resolve_to_mbti(raw_pred, cluster_map: Dict[int, str]) -> str:
    if isinstance(raw_pred, (np.generic,)): raw_pred = raw_pred.item()
    if isinstance(raw_pred, str):
        key = _norm_str(raw_pred)
        if key in ALIAS_TO_TYPE:
            return ALIAS_TO_TYPE[key]
        if key.isdigit():
            return cluster_map.get(int(key), str(raw_pred))
        return str(raw_pred)
    if isinstance(raw_pred, (int, np.integer)):
        return cluster_map.get(int(raw_pred), str(raw_pred))
    return str(raw_pred)

def aggregate_probs_by_type(classes, probs, cluster_map: Dict[int, str]) -> pd.DataFrame:
    """
    ëª¨ë¸ í´ë˜ìŠ¤ í™•ë¥ ì„ ESFJ/ESTJ/INTP/INFPë¡œ ëª¨ì•„ ì§‘ê³„í•˜ê³ ,
    ì§‘ê³„í•©ìœ¼ë¡œ ì •ê·œí™”(í•©ê³„ 1.0)í•˜ì—¬ ë°˜í™˜.
    """
    label_probs: Dict[str, float] = {"ESFJ":0.0, "ESTJ":0.0, "INTP":0.0, "INFP":0.0}

    for c, p in zip(classes, probs):
        mapped = resolve_to_mbti(c, cluster_map)
        if mapped in label_probs:
            label_probs[mapped] += float(p)
        # ë§¤í•‘ë˜ì§€ ì•ŠëŠ” í´ë˜ìŠ¤ëŠ” ë¬´ì‹œ(= ì§‘ê³„í•©ì—ì„œ ìë™ ì œì™¸)

    total = sum(label_probs.values())
    if total > 0:
        for k in label_probs:
            label_probs[k] /= total

    dfp = pd.DataFrame({"class": list(label_probs.keys()), "prob": list(label_probs.values())})
    return dfp.sort_values("prob", ascending=False)

def render_combined_profile(label: str):
    mbti = mbti_letters(label)
    alias = TYPE_ALIAS.get(mbti, "")
    bullets = [DIM_DESC[ch] for ch in mbti if ch in DIM_DESC]
    summary = SUMMARY_LINE.get(mbti, "")
    st.markdown(
        f"""
        <div style="border:1px solid #eee;border-radius:14px;padding:16px 18px;margin:8px 0;">
          <div style="font-size:1.1rem;font-weight:700;margin-bottom:6px;">
            {mbti} {f"({alias})" if alias else ""}
          </div>
          <ul style="margin:0 0 0 1.1rem;">
            {''.join(f'<li style="margin:2px 0;">{b}</li>' for b in bullets)}
          </ul>
          <div style="margin-top:8px;"><b>ìš”ì•½:</b> {summary}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

# ---- ë§‰ëŒ€ ë¼ë²¨: í•­ìƒ ë§‰ëŒ€ ìœ„(ê²€ì •) + ìƒë‹¨ ì—¬ìœ  ----
def plot_probs_with_labels(prob_df: pd.DataFrame):
    if prob_df is None or prob_df.empty:
        return
    labels = prob_df["class"].tolist()
    vals   = prob_df["prob"].tolist()
    perc   = [v * 100 for v in vals]

    fig, ax = plt.subplots(figsize=(7, 3.6))
    bars = ax.bar(labels, vals)
    ax.set_ylim(0, 1.08)
    ax.set_ylabel("Probability")

    for i, b in enumerate(bars):
        h = b.get_height()
        y = min(h + 0.03, 1.05)
        ax.text(b.get_x() + b.get_width()/2, y, f"{perc[i]:.1f}%",
                ha="center", va="bottom", color="black", fontweight="bold", fontsize=11)

    st.pyplot(fig, clear_figure=True)

# ================================
# Data & Preprocess
# ================================
@st.cache_data(show_spinner=False)
def load_raw() -> Tuple[pd.DataFrame, pd.DataFrame]:
    df1 = pd.read_csv(FIRST_CSV)
    df2 = pd.read_csv(SECOND_CSV)  # row0 has labels for X6+
    return df1, df2

def _rename_second_like_training(df2: pd.DataFrame) -> pd.DataFrame:
    df2 = df2.copy()
    df2 = df2.rename(columns={df2.columns[0]: "panel_id"})
    rename_map = {old: f"X{i+1}" for i, old in enumerate(df2.columns[1:])}
    df2 = df2.rename(columns=rename_map)
    return df2

def build_human_label_map(df2_raw: pd.DataFrame) -> Dict[str, str]:
    labels_row = df2_raw.iloc[0]
    colnames   = list(df2_raw.columns)
    friendly: Dict[str, str] = {}
    for idx, col in enumerate(colnames[1:], start=1):
        if idx >= 6:
            friendly[f"X{idx}"] = str(labels_row[col])
    return friendly

@st.cache_data(show_spinner=False)
def prepare_training_schema() -> Tuple[List[str], Dict[str, str]]:
    df1_raw, df2_raw = load_raw()
    allowed_ids = set(df1_raw['panel_id'].astype(str))
    df2 = df2_raw[df2_raw.iloc[:, 0].astype(str).isin(allowed_ids)].reset_index(drop=True)
    x_label_map = build_human_label_map(df2_raw)
    df2 = _rename_second_like_training(df2)
    for cat in ["X1", "X2", "X3"]:
        if cat in df2.columns:
            df2[cat] = pd.to_numeric(df2[cat], errors="coerce")
    df2 = pd.get_dummies(df2, columns=["X1", "X2", "X3"], drop_first=True, dtype=int)
    merged = pd.merge(df1_raw, df2, on="panel_id", how="inner")
    feature_cols = [c for c in merged.columns if c not in ["panel_id", "cluster"]]
    return feature_cols, x_label_map

# ================================
# Model loader (with fallback)
# ================================
@st.cache_resource(show_spinner=False)
def load_or_train_model(feature_cols: List[str]):
    model = None
    try:
        with open(MODEL_PKL, "rb") as f:
            model = pickle.load(f)
    except Exception:
        from sklearn.ensemble import RandomForestClassifier
        df1_raw, df2_raw = load_raw()
        allowed_ids = set(df1_raw['panel_id'].astype(str))
        df2 = _rename_second_like_training(df2)
        for cat in ["X1", "X2", "X3"]:
            if cat in df2.columns:
                df2[cat] = pd.to_numeric(df2[cat], errors="coerce")
        df2 = pd.get_dummies(df2, columns=["X1", "X2", "X3"], drop_first=True, dtype=int)
        merged = pd.merge(df1_raw, df2, on="panel_id", how="inner")
        X = merged[feature_cols].to_numpy()
        y = merged["cluster"].to_numpy()
        rf = RandomForestClassifier(random_state=0)
        rf.fit(X, y)
        model = rf
    return model

# ================================
# ì…ë ¥í–‰ ìƒì„± ìœ í‹¸
# ================================
def empty_feature_row(feature_cols: List[str]) -> pd.DataFrame:
    return pd.DataFrame([np.zeros(len(feature_cols), dtype=float)], columns=feature_cols)

def build_manual_row(
    feature_cols: List[str],
    base_nums: Dict[str, float],
    x123_values: Dict[str, int],
    onoff_map: Dict[str, int]
) -> pd.DataFrame:
    row = empty_feature_row(feature_cols)
    for k, v in base_nums.items():
        if k in row.columns: row.at[0, k] = float(v)
    for xk, val in x123_values.items():
        if val is None: continue
        col_name = f"{xk}_{val}"
        if col_name in row.columns: row.at[0, col_name] = 1.0
    for xk, onoff in onoff_map.items():
        if xk in row.columns: row.at[0, xk] = int(onoff)
    return row

# ================================
# UI
# ================================
st.set_page_config(page_title="OTT ì´ìš©ì êµ°ì§‘ ì˜ˆì¸¡", layout="wide")

# session state
if "started" not in st.session_state:
    st.session_state.started = False
if "show_modal" not in st.session_state:
    st.session_state.show_modal = False
if "modal_token" not in st.session_state:
    st.session_state.modal_token = 0
if "modal_last_shown" not in st.session_state:
    st.session_state.modal_last_shown = -1

# ---- ì»¤ë²„ ----
if not st.session_state.started:
    st.markdown(
        """
        <style>
        .cover-wrap { height: 45vh; display:flex; align-items:center; justify-content:center; text-align:center; }
        .cover-inner h1 { font-size:3rem; margin-bottom:.25rem; }
        .cover-inner p  { font-size:1.05rem; color:#555; margin-bottom:1rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.markdown(
        """
        <div class="cover-wrap">
          <div class="cover-inner">
            <h1>ğŸ“º OTT ì´ìš©ì êµ°ì§‘ ì˜ˆì¸¡</h1>
            <p>ì´ìš© íŒ¨í„´ê³¼ ì„ í˜¸ ì¥ë¥´ë¥¼ ì…ë ¥í•˜ë©´ êµ°ì§‘ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.</p>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )
    start_col = st.columns([1,1,1])[1]
    with start_col:
        if st.button("ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
            st.session_state.started = True
            st.rerun()
    st.stop()

st.title("ğŸ“º OTT ì´ìš©ì êµ°ì§‘ ì˜ˆì¸¡")

with st.sidebar:
    st.header("ì„¤ì •")
    FEATURE_COLS, X_LABELS = prepare_training_schema()
    model = load_or_train_model(FEATURE_COLS)
    st.success("ìŠ¤í‚¤ë§ˆ & ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ âœ…")

    if "cluster_to_type" not in st.session_state:
        st.session_state.cluster_to_type = DEFAULT_CLUSTER_TO_TYPE.copy()

    with st.expander("ë¼ë²¨ ë§¤í•‘ (ìˆ«ì/ë³„ì¹­ì¼ ë•Œ ì¡°ì •)"):
        classes = getattr(model, "classes_", None)
        if classes is not None:
            st.caption(f"model.classes_: {list(classes)}")
        for k in sorted(st.session_state.cluster_to_type.keys()):
            st.session_state.cluster_to_type[k] = st.selectbox(
                f"í´ëŸ¬ìŠ¤í„° {k} â†’ ìœ í˜•",
                options=list(TYPE_ALIAS.keys()),
                index=list(TYPE_ALIAS.keys()).index(st.session_state.cluster_to_type[k]),
                key=f"map_{k}"
            )

# ================================
# ì…ë ¥ë¶€: (ì‹œê°„)(ë¶„) ìŒ â€“ ë™ì¼ ë„ˆë¹„, ë©”ì´ì €/ë§ˆì´ë„ˆ íˆ´íŒ
# ================================
st.markdown("### ì´ìš© íŒ¨í„´ ì…ë ¥")

def time_pair_in_columns(col_h, col_m, title: str, key: str, max_h: int = 72, help_text: str | None = None) -> float:
    with col_h:
        hh = st.number_input(f"{title} (ì‹œê°„)", min_value=0, max_value=max_h, value=0, step=1,
                             key=f"{key}_h", help=help_text)
    with col_m:
        mm = st.number_input("(ë¶„)", min_value=0, max_value=59, value=0, step=5, key=f"{key}_m")
    return float(hh) + float(mm)/60.0

# 1í–‰: Major OTT | Minor OTT  (ê° ë¼ë²¨ì— ì˜ˆì‹œ íˆ´íŒ)
r1c1, r1c2, r1c3, r1c4 = st.columns(4)
major_ott = time_pair_in_columns(r1c1, r1c2, "Major OTT", "major", help_text=MAJOR_HELP)
minor_ott = time_pair_in_columns(r1c3, r1c4, "Minor OTT", "minor", help_text=MINOR_HELP)

# 2í–‰: YouTube | ìŠ¤í¬ì¸ 
r2c1, r2c2, r2c3, r2c4 = st.columns(4)
youtube = time_pair_in_columns(r2c1, r2c2, "YouTube", "yt")
sports  = time_pair_in_columns(r2c3, r2c4, "ìŠ¤í¬ì¸ ", "sports")

# 3í–‰: ì‡¼í•‘ / ì‚¬ìš© OTT ìˆ˜
r3c1, r3c2 = st.columns(2)
with r3c1:
    shopping = st.number_input("ì‡¼í•‘ (ì£¼ë‹¹ ì´ìš© íšŸìˆ˜, íšŒ)",
                               min_value=0, max_value=70, value=0, step=1, format="%d", key="shop")
with r3c2:
    media_ott_val = st.selectbox("ì‚¬ìš© OTT ìˆ˜ (ê°œ)", options=list(range(0, 11)), index=0,
                                 help="ë™ì‹œì— ì‚¬ìš©í•˜ëŠ” OTT ì„œë¹„ìŠ¤ ê°œìˆ˜")

# ================================
# TV ì¥ë¥´(X1~X3) + ë™ì˜ìƒ ì¥ë¥´ ì²´í¬
# ================================
st.markdown("### ì„ í˜¸ TV ì¥ë¥´ ì„ íƒ")
colx1, colx2, colx3 = st.columns(3)
genre_options = list(GENRE_MAP.values())
with colx1:
    x1_label = st.selectbox("1ìˆœìœ„ ì¥ë¥´", options=genre_options, index=0)
with colx2:
    x2_label = st.selectbox("2ìˆœìœ„ ì¥ë¥´", options=genre_options, index=0)
with colx3:
    x3_label = st.selectbox("3ìˆœìœ„ ì¥ë¥´", options=genre_options, index=0)

st.markdown("### ì„ í˜¸ ë™ì˜ìƒ ì½˜í…ì¸  ì¥ë¥´ (ì¤‘ë³µì²´í¬)")
x_onoff_cols = [c for c in FEATURE_COLS if c.startswith("X") and c[1:].isdigit() and int(c[1:]) >= 6]
onoff_selections: Dict[str, int] = {}
cols = st.columns(3)
for i, colname in enumerate(sorted(x_onoff_cols, key=lambda s: int(s[1:]))):
    label = X_LABELS.get(colname, colname)
    with cols[i % 3]:
        val = st.checkbox(label, value=False, key=f"on_{colname}")
        onoff_selections[colname] = val

# ================================
# ê²°ê³¼ ëª¨ë‹¬(dialog)
# ================================
def _result_body(pred_label: str, prob_df: pd.DataFrame | None):
    st.success(f"ì˜ˆì¸¡ êµ°ì§‘: **{pred_label}**")
    render_combined_profile(pred_label)
    if prob_df is not None and not prob_df.empty:
        st.markdown("---")
        st.caption("í´ë˜ìŠ¤ í™•ë¥ (4ìœ í˜• ì§‘ê³„)")
        plot_probs_with_labels(prob_df)

HAS_DIALOG = hasattr(st, "dialog")

if HAS_DIALOG:
    @st.dialog("ì˜ˆì¸¡ ê²°ê³¼", width="large")
    def show_result_dialog():
        pred_label = st.session_state.get("result_label")
        prob_df = st.session_state.get("result_probs")
        _result_body(pred_label, prob_df)
        st.divider()
        if st.button("ë‹«ê¸°", use_container_width=True):
            st.session_state.show_modal = False
            st.rerun()
else:
    def show_result_dialog():
        st.markdown("""
        <style>
        .overlay { position:fixed; top:0; left:0; width:100%; height:100%; background: rgba(0,0,0,.35); z-index:1000; }
        .modal { position:fixed; top: 8vh; left:50%; transform:translateX(-50%);
                 width:min(860px,94vw); background:#fff; border-radius:14px; box-shadow:0 10px 30px rgba(0,0,0,.2);
                 padding:18px 20px; z-index:1001; }
        </style>
        """, unsafe_allow_html=True)
        st.markdown('<div class="overlay"></div><div class="modal">', unsafe_allow_html=True)
        pred_label = st.session_state.get("result_label")
        prob_df = st.session_state.get("result_probs")
        _result_body(pred_label, prob_df)
        if st.button("ë‹«ê¸°", use_container_width=True):
            st.session_state.show_modal = False
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)

# ================================
# ì˜ˆì¸¡ ì‹¤í–‰
# ================================
if st.button("ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
    base_nums = {
        "Major OTT": major_ott,
        "Minor OTT": minor_ott,
        "YouTube": youtube,
        "ìŠ¤í¬ì¸ ": sports,
        "ì‡¼í•‘": float(shopping),
        "ë¯¸ë””ì–´_OTT": float(media_ott_val),   # ë‚´ë¶€ ì»¬ëŸ¼ëª…ì€ ê¸°ì¡´ ìœ ì§€
    }
    x123_vals = {
        "X1": GENRE_LABEL_TO_CODE.get(x1_label),
        "X2": GENRE_LABEL_TO_CODE.get(x2_label),
        "X3": GENRE_LABEL_TO_CODE.get(x3_label),
    }

    Xrow = build_manual_row(FEATURE_COLS, base_nums, x123_vals, onoff_selections)
    raw_pred = model.predict(Xrow.to_numpy())[0]
    pred_label = resolve_to_mbti(raw_pred, st.session_state.cluster_to_type)

    prob_df = None
    if hasattr(model, "predict_proba"):
        try:
            probs = model.predict_proba(Xrow.to_numpy())[0]
            classes = getattr(model, "classes_", None)
            if classes is not None:
                prob_df = aggregate_probs_by_type(classes, probs, st.session_state.cluster_to_type)
        except Exception:
            pass

    st.session_state.result_label = pred_label
    st.session_state.result_probs = prob_df
    st.session_state.show_modal = True
    st.session_state.modal_token += 1  # ì´ë²ˆ ì‹¤í–‰ í† í° ê°±ì‹ 

# í† í° ë°©ì‹: ê°™ì€ í† í°ì—ì„œëŠ” 1ë²ˆë§Œ ëª¨ë‹¬ í‘œì‹œ
if st.session_state.show_modal:
    token = st.session_state.modal_token
    if st.session_state.modal_last_shown != token:
        show_result_dialog()
        st.session_state.modal_last_shown = token







