import os
import pickle
from typing import Dict, List, Tuple
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st

# ================================
# Paths
# ================================
APP_DIR = Path(__file__).parent.resolve()
FIRST_CSV   = APP_DIR / "first.csv"
SECOND_CSV  = APP_DIR / "second.csv"
MODEL_PKL   = APP_DIR / "model.pkl"

# ================================
# Genre map
# ================================
GENRE_MAP = {
    1: "ë²„ë¼ì´ì–´í‹°/ì˜ˆëŠ¥",
    2: "ë“œë¼ë§ˆ",
    3: "ë‰´ìŠ¤",
    4: "ìŠ¤í¬ì¸ ",
    5: "ì·¨ë¯¸/ë ˆì €",
    6: "ìŒì•…",
    7: "êµìœ¡",
    8: "ì‹œì‚¬/ë‹¤í",
    9: "êµì–‘/ì •ë³´",
    10: "í™ˆì‡¼í•‘",
    11: "ì„±ì¸",
    997: "ê¸°íƒ€"
}
GENRE_LABEL_TO_CODE = {v: k for k, v in GENRE_MAP.items()}

# ================================
# (ì˜µì…˜) íƒ€ì… ì„¤ëª… ì¹´ë“œ (ì´ì „ê³¼ ë™ì¼)
# ================================
TYPE_DESC = {
    "ESFJ": {"alias":"ENGAGED","bullets":[
        "ì•± í™œìš©ë„ ë†’ìŒÂ·ì‚¬íšŒì„± ê°•í•¨ (íŠ¸ë Œë“œ/ì¶”ì²œì— ë¯¼ê°)",
        "ëª¨ë°”ì¼ ì•± ì¤‘ì‹¬, ì£¼ ì‚¬ìš© ì‹œê°„ ë§ìŒ",
        "ë²„ë¼ì´ì–´í‹°/ì˜ˆëŠ¥Â·ìŒì•…Â·ë¼ì´í”„ìŠ¤íƒ€ì¼ ì„ í˜¸",
        "í•œ ì¤„: ì¬ë¯¸ì™€ ì¦ê±°ì›€ì„ ì ê·¹ì ìœ¼ë¡œ ì¶”êµ¬"
    ]},
    "ESTJ": {"alias":"PLANNED","bullets":[
        "ìê¸°ê´€ë¦¬Â·ê·œìœ¨, ì‹œì²­ ì‹œê°„ì„ ê³„íšì ìœ¼ë¡œ ê´€ë¦¬",
        "ë£¨í‹´ ê¸°ë°˜ ê·œì¹™ì  ì´ìš©, ë¶ˆí•„ìš” í”Œë«í¼ ì •ë¦¬",
        "ë‰´ìŠ¤/ì‹œì‚¬Â·êµì–‘/ì •ë³´Â·êµìœ¡ ë“± ì‹¤ìš© ì •ë³´ ì„ í˜¸",
        "í•œ ì¤„: ì²´ê³„ì Â·ëª©ì í˜• OTT ì‚¬ìš©"
    ]},
    "INTP": {"alias":"TARGETED","bullets":[
        "ë¶„ì„ì Â·ì§‘ì¤‘í˜•, íŠ¹ì • ì£¼ì œì— ê¹Šê²Œ ëª°ì…",
        "ì „ì²´ ì‹œê°„ì€ ê¸¸ì§€ ì•Šì•„ë„ ì„ íƒ ì‹œ ê³ ë°€ë„ ì§‘ì¤‘",
        "ë‹¤íÂ·ì§€ì‹Â·ì‹œë¦¬ì¦ˆ ë“± ì‹¬ì¸µ ì½˜í…ì¸  ì„ í˜¸",
        "í•œ ì¤„: ê´€ì‹¬ ë¶„ì•¼ë§Œ ë‚ ì¹´ë¡­ê²Œ íŒŒê³ ë“¦"
    ]},
    "INFP": {"alias":"JOYFUL","bullets":[
        "ê°ì„±Â·ììœ ì§€í–¥, ê¸°ë¶„ ì „í™˜ìš© ì¦‰í¥ ì‹œì²­",
        "ì‹œê°„ ê´€ë¦¬ ì—„ê²©í•˜ì§„ ì•ŠìŒ, ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ ëª©ì ",
        "ë“œë¼ë§ˆÂ·ë¡œë§¨ìŠ¤Â·íë§ ì˜ˆëŠ¥Â·ìŒì•… ì„ í˜¸",
        "í•œ ì¤„: ì¦ê±°ì›€ ì¤‘ì‹¬ì˜ ììœ ë¡œìš´ ì„ íƒ"
    ]},
}

def render_type_card(label: str):
    info = TYPE_DESC.get(label)
    if not info:
        return
    st.markdown(
        f"""
        <div style="border:1px solid #eee;border-radius:14px;padding:16px 18px;margin-top:8px;">
          <div style="font-size:1.1rem;font-weight:700;margin-bottom:6px;">
            {label} <span style="opacity:.6;">({info['alias']})</span>
          </div>
          <ul style="margin:0 0 0 1.1rem;">
            {''.join(f'<li style="margin:2px 0;">{b}</li>' for b in info['bullets'])}
          </ul>
        </div>
        """,
        unsafe_allow_html=True,
    )

# ================================
# NEW) MBTI 4ì¶•( E/I, S/N, T/F, J/P ) ì„¤ëª… ì¡°í•©
# ================================
DIM_DESC = {
    "E": "ì™¸í–¥: OTT ì‚¬ìš©ëŸ‰ì´ ë§ê³  ë‹¤ì–‘í•œ ì•±ì„ **ì ê·¹ì ìœ¼ë¡œ í™œìš©**í•©ë‹ˆë‹¤.",
    "I": "ë‚´í–¥: OTT ì‚¬ìš©ëŸ‰ì´ ì ê³  í˜¼ì ë³´ëŠ” **ì„ íƒì Â·ì¡°ìš©í•œ ì´ìš©**ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
    "S": "ê°ê°(S): **ëª¨ë°”ì¼ ì•± ì¤‘ì‹¬**ìœ¼ë¡œ ì¼ìƒ ì†ì— ìì—°ìŠ¤ëŸ½ê²Œ OTTë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
    "N": "ì§ê´€(N): **ì—”í„°í…Œì¸ë¨¼íŠ¸/ë¯¸ë””ì–´ ë°©ì‹**ìœ¼ë¡œ í˜¸ê¸°ì‹¬ì— ë”°ë¼ í­ë„“ê²Œ íƒìƒ‰í•©ë‹ˆë‹¤.",
    "T": "ì‚¬ê³ (T): **ì‹¤ìš©ì„±ê³¼ í•„ìš”ì„±**ì„ ì¤‘ì‹œí•˜ë©° íš¨ìœ¨ì ìœ¼ë¡œ ì½˜í…ì¸ ë¥¼ ê³ ë¦…ë‹ˆë‹¤.",
    "F": "ê°ì •(F): **ì¦ê±°ì›€Â·ê³µê°**ì„ ì¤‘ì‹œí•˜ë©° ê°ì •ì  ë§Œì¡±ì„ ìœ„í•´ ì‹œì²­í•©ë‹ˆë‹¤.",
    "J": "íŒë‹¨(J): **ìê¸°ê´€ë¦¬ì™€ ê³„íš**ì„ ì„¸ì›Œ ì‹œì²­ íŒ¨í„´ì„ ê¾¸ì¤€íˆ ìœ ì§€í•©ë‹ˆë‹¤.",
    "P": "ì¸ì‹(P): **ììœ Â·ì¦‰í¥ì **ìœ¼ë¡œ ìƒí™©ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì‹œì²­í•©ë‹ˆë‹¤.",
}

def mbti_letters(label: str) -> str:
    """ë¼ë²¨ì—ì„œ MBTI 4ê¸€ìë§Œ ì¶”ì¶œ(ESFJ ë“±)."""
    s = "".join(ch for ch in str(label).upper() if ch.isalpha())
    # ì²« 4ìë¦¬ê°€ E/I S/N T/F J/P íŒ¨í„´ì´ë©´ ê·¸ê±¸ ì‚¬ìš©
    if len(s) >= 4:
        four = s[:4]
        ok = (four[0] in "EI") and (four[1] in "SN") and (four[2] in "TF") and (four[3] in "JP")
        return four if ok else s[:4]
    return s

def compose_mbti_explanation(label: str) -> Dict[str, str]:
    """ESFJ â†’ ì¶•ë³„ ì„¤ëª… 4ê°œ + ìš”ì•½ë¬¸ ìƒì„±."""
    mbti = mbti_letters(label)
    parts = []
    for ch in mbti[:4]:
        if ch in DIM_DESC:
            parts.append(DIM_DESC[ch])
    # ìš”ì•½ í•œ ë¬¸ì¥(ê°„ë‹¨ í…œí”Œë¦¿)
    if len(mbti) >= 4:
        summary = {
            "ESFJ": "í™œë°œí•œ ì‚¬êµì„±(E)+ì¼ìƒì  ì•± í™œìš©(S)+ì¦ê±°ì›€ ì§€í–¥(F)+ê³„íšì  ê´€ë¦¬(J)ì˜ ì¡°í•©ìœ¼ë¡œ, ë§ì´ ì¦ê¸°ë˜ ì§ˆì„œ ìˆê²Œ ì‚¬ìš©í•˜ëŠ” íƒ€ì…ì…ë‹ˆë‹¤.",
            "ESTJ": "ì™¸í–¥(E)+ê°ê°(S)+ì‹¤ìš© ì§€í–¥(T)+ê³„íšì (J) ì¡°í•©ìœ¼ë¡œ, ëª©ì ê³¼ íš¨ìœ¨ ì¤‘ì‹¬ì˜ ì²´ê³„ì  ì‚¬ìš©ìì…ë‹ˆë‹¤.",
            "INTP": "ë‚´í–¥(I)+ì§ê´€(N)+ë¶„ì„ì (T)+ìœ ì—°(P) ì¡°í•©ìœ¼ë¡œ, ì ì€ ì–‘ì„ ì„ íƒÂ·ì§‘ì¤‘í•´ ê¹Šê²Œ íŒŒëŠ” íƒêµ¬í˜• ì‚¬ìš©ìì…ë‹ˆë‹¤.",
            "INFP": "ë‚´í–¥(I)+ì§ê´€(N)+ê°ì„±(F)+ìœ ì—°(P) ì¡°í•©ìœ¼ë¡œ, ê°ì • ì´ì…ê³¼ íœ´ì‹ì„ ìœ„í•´ ììœ ë¡­ê²Œ ì‹œì²­í•˜ëŠ” ì‚¬ìš©ìì…ë‹ˆë‹¤.",
        }.get(mbti[:4], "")
    else:
        summary = ""
    return {"mbti": mbti[:4], "bullets": parts, "summary": summary}

def render_mbti_combo(label: str):
    """í™”ë©´ ì¶œë ¥ìš©: ì¶•ë³„ ì„¤ëª… 4ê°œì™€ ìš”ì•½."""
    combo = compose_mbti_explanation(label)
    if len(combo["mbti"]) != 4 or not combo["bullets"]:
        st.info("ì˜ˆì¸¡ ë¼ë²¨ì—ì„œ MBTI 4ê¸€ìë¥¼ í™•ì¸í•˜ì§€ ëª»í•´ ì¡°í•© ì„¤ëª…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    st.subheader(f"MBTI ì¡°í•© ì„¤ëª…: {combo['mbti']}")
    cols = st.columns(2)
    for i, b in enumerate(combo["bullets"]):
        with cols[i % 2]:
            st.markdown(f"- {b}")
    if combo["summary"]:
        st.markdown(f"**ìš”ì•½:** {combo['summary']}")

# ================================
# Data & Preprocess
# ================================
@st.cache_data(show_spinner=False)
def load_raw() -> Tuple[pd.DataFrame, pd.DataFrame]:
    df1 = pd.read_csv(FIRST_CSV)
    df2 = pd.read_csv(SECOND_CSV)  # row0 has labels for X6+
    return df1, df2

def _rename_second_like_training(df2: pd.DataFrame) -> pd.DataFrame:
    df2 = df2.copy()
    df2 = df2.rename(columns={df2.columns[0]: "panel_id"})
    rename_map = {old: f"X{i+1}" for i, old in enumerate(df2.columns[1:])}
    df2 = df2.rename(columns=rename_map)
    return df2

def build_human_label_map(df2_raw: pd.DataFrame) -> Dict[str, str]:
    labels_row = df2_raw.iloc[0]
    colnames   = list(df2_raw.columns)
    friendly: Dict[str, str] = {}
    for idx, col in enumerate(colnames[1:], start=1):
        if idx >= 6:
            friendly[f"X{idx}"] = str(labels_row[col])
    return friendly

@st.cache_data(show_spinner=False)
def prepare_training_schema() -> Tuple[List[str], Dict[str, str]]:
    df1_raw, df2_raw = load_raw()
    allowed_ids = set(df1_raw['panel_id'].astype(str))
    df2 = df2_raw[df2_raw.iloc[:, 0].astype(str).isin(allowed_ids)].reset_index(drop=True)

    x_label_map = build_human_label_map(df2_raw)

    df2 = _rename_second_like_training(df2)
    for cat in ["X1", "X2", "X3"]:
        if cat in df2.columns:
            df2[cat] = pd.to_numeric(df2[cat], errors="coerce")
    df2 = pd.get_dummies(df2, columns=["X1", "X2", "X3"], drop_first=True, dtype=int)

    merged = pd.merge(df1_raw, df2, on="panel_id", how="inner")
    feature_cols = [c for c in merged.columns if c not in ["panel_id", "cluster"]]
    return feature_cols, x_label_map

# ================================
# Model loader (with fallback)
# ================================
@st.cache_resource(show_spinner=False)
def load_or_train_model(feature_cols: List[str]):
    model = None
    try:
        with open(MODEL_PKL, "rb") as f:
            model = pickle.load(f)
    except Exception:
        from sklearn.ensemble import RandomForestClassifier
        df1_raw, df2_raw = load_raw()
        allowed_ids = set(df1_raw['panel_id'].astype(str))
        df2 = df2_raw[df2_raw.iloc[:, 0].astype(str).isin(allowed_ids)].reset_index(drop=True)
        df2 = _rename_second_like_training(df2)
        for cat in ["X1", "X2", "X3"]:
            if cat in df2.columns:
                df2[cat] = pd.to_numeric(df2[cat], errors="coerce")
        df2 = pd.get_dummies(df2, columns=["X1", "X2", "X3"], drop_first=True, dtype=int)
        merged = pd.merge(df1_raw, df2, on="panel_id", how="inner")
        X = merged[feature_cols].to_numpy()
        y = merged["cluster"].to_numpy()
        rf = RandomForestClassifier(random_state=0)
        rf.fit(X, y)
        model = rf
    return model

# ================================
# Utilities
# ================================
def empty_feature_row(feature_cols: List[str]) -> pd.DataFrame:
    return pd.DataFrame([np.zeros(len(feature_cols), dtype=float)], columns=feature_cols)

def build_manual_row(
    feature_cols: List[str],
    base_nums: Dict[str, float],
    x123_values: Dict[str, int],
    onoff_map: Dict[str, int]
) -> pd.DataFrame:
    row = empty_feature_row(feature_cols)
    for k, v in base_nums.items():
        if k in row.columns:
            row.at[0, k] = float(v)
    for xk, val in x123_values.items():
        if val is None:
            continue
        col_name = f"{xk}_{val}"
        if col_name in row.columns:
            row.at[0, col_name] = 1.0
    for xk, onoff in onoff_map.items():
        if xk in row.columns:
            row.at[0, xk] = int(onoff)
    return row

# ================================
# UI
# ================================
st.set_page_config(page_title="OTT ì´ìš©ì êµ°ì§‘ ì˜ˆì¸¡", layout="wide")

# ---- Cover page (centered) ----
if "started" not in st.session_state:
    st.session_state.started = False

if not st.session_state.started:
    st.markdown(
        """
        <style>
        .cover-wrap {
            height: 60vh;  /* 80vh -> 60vh */
            display: flex; align-items: center; justify-content: center; text-align: center;
        }
        .cover-inner h1 { font-size: 3rem; margin-bottom: .25rem; }
        .cover-inner p  { font-size: 1.05rem; color: #555; margin-bottom: 1.25rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.markdown(
        """
        <div class="cover-wrap">
          <div class="cover-inner">
            <h1>ğŸ“º OTT ì´ìš©ì êµ°ì§‘ ì˜ˆì¸¡</h1>
            <p>ì´ìš© íŒ¨í„´ê³¼ ì„ í˜¸ ì¥ë¥´ë¥¼ ì…ë ¥í•˜ë©´ êµ°ì§‘ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.</p>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )
    start_col = st.columns([1,1,1])[1]
    with start_col:
        if st.button("ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
            st.session_state.started = True
            st.rerun()
    st.stop()

# ---- Prediction page ----
st.title("ğŸ“º OTT ì´ìš©ì êµ°ì§‘ ì˜ˆì¸¡")

with st.sidebar:
    st.header("ì„¤ì •")
    FEATURE_COLS, X_LABELS = prepare_training_schema()
    model = load_or_train_model(FEATURE_COLS)
    st.success("ìŠ¤í‚¤ë§ˆ & ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ âœ…")

# ================================
# Friendly input widgets
# ================================
def time_hours_widget(label: str, key: str, minute_mode: bool, max_h: int = 70) -> float:
    if not minute_mode:
        return st.slider(label, min_value=0.0, max_value=float(max_h),
                         value=0.0, step=0.25, key=key,
                         help="15ë¶„=0.25h, 30ë¶„=0.5h, 1ì‹œê°„=1.0h")
    else:
        c_h, c_m = st.columns([2,1])
        with c_h:
            hh = st.number_input(f"{label} (ì‹œê°„)", min_value=0, max_value=max_h, value=0, step=1, key=f"{key}_h")
        with c_m:
            mm = st.number_input(f"{label} (ë¶„)",   min_value=0, max_value=59, value=0, step=5, key=f"{key}_m")
        return float(hh) + float(mm)/60.0

def count_per_week_widget(label: str, key: str, max_cnt: int = 70) -> int:
    return st.number_input(label, min_value=0, max_value=max_cnt, value=0, step=1, format="%d", key=key)

# ================================
# ì…ë ¥ ì˜ì—­
# ================================
st.markdown("### ì´ìš© íŒ¨í„´ ì…ë ¥")
minute_mode = st.toggle("ì‹œ/ë¶„ìœ¼ë¡œ ì…ë ¥í• ë˜ìš”? (ë„ë©´ 15ë¶„ ë‹¨ìœ„ ìŠ¬ë¼ì´ë”)", value=False)

c1, c2, c3 = st.columns(3)
with c1:
    major_ott = time_hours_widget("Major OTT (ì£¼ë‹¹ ì‹œì²­ì‹œê°„, ì‹œê°„)", key="major", minute_mode=minute_mode)
    youtube   = time_hours_widget("YouTube (ì£¼ë‹¹ ì‹œì²­ì‹œê°„, ì‹œê°„)",   key="yt",    minute_mode=minute_mode)
with c2:
    minor_ott = time_hours_widget("Minor OTT (ì£¼ë‹¹ ì‹œì²­ì‹œê°„, ì‹œê°„)", key="minor", minute_mode=minute_mode)
    shopping  = count_per_week_widget("ì‡¼í•‘ (ì£¼ë‹¹ ì´ìš© íšŸìˆ˜, íšŒ)",     key="shop")
with c3:
    sports    = time_hours_widget("ìŠ¤í¬ì¸  (ì£¼ë‹¹ ì‹œì²­ì‹œê°„, ì‹œê°„)",     key="sports", minute_mode=minute_mode)
    media_ott_val = st.selectbox("ë¯¸ë””ì–´_OTT (ì‚¬ìš© OTT ìˆ˜)", options=list(range(0, 11)), index=0,
                                 help="ë™ì‹œì— ì‚¬ìš©í•˜ëŠ” OTT ì„œë¹„ìŠ¤ì˜ ê°œìˆ˜")

st.caption("â€» ì‹œì²­ì‹œê°„ì€ 'ì‹œê°„' ë‹¨ìœ„ë¡œ ëª¨ë¸ì— ë“¤ì–´ê°‘ë‹ˆë‹¤. (ì˜ˆ: 1ì‹œê°„ 30ë¶„ â†’ 1.5ì‹œê°„)")

# ================================
# TV ì¥ë¥´(X1,X2,X3) + ë™ì˜ìƒ ì¥ë¥´ ì²´í¬
# ================================
st.markdown("### TV ì¥ë¥´ ìˆœìœ„ ì„ íƒ (X1, X2, X3)")
colx1, colx2, colx3 = st.columns(3)
genre_options = list(GENRE_MAP.values())
with colx1:
    x1_label = st.selectbox("1ìˆœìœ„ ì¥ë¥´", options=genre_options, index=0)
with colx2:
    x2_label = st.selectbox("2ìˆœìœ„ ì¥ë¥´", options=genre_options, index=0)
with colx3:
    x3_label = st.selectbox("3ìˆœìœ„ ì¥ë¥´", options=genre_options, index=0)

st.markdown("### ë™ì˜ìƒ ì½˜í…ì¸  ì¥ë¥´ (í•´ë‹¹ ì‹œ ì²´í¬)")
x_onoff_cols = [c for c in FEATURE_COLS if c.startswith("X") and c[1:].isdigit() and int(c[1:]) >= 6]
onoff_selections: Dict[str, int] = {}
cols = st.columns(3)
for i, colname in enumerate(sorted(x_onoff_cols, key=lambda s: int(s[1:]))):
    label = X_LABELS.get(colname, colname)
    with cols[i % 3]:
        onoff_selections[colname] = st.checkbox(label, value=False)

# ================================
# ì˜ˆì¸¡ ì‹¤í–‰
# ================================
if st.button("ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
    base_nums = {
        "Major OTT": major_ott,
        "Minor OTT": minor_ott,
        "YouTube": youtube,
        "ìŠ¤í¬ì¸ ": sports,
        "ì‡¼í•‘": float(shopping),
        "ë¯¸ë””ì–´_OTT": float(media_ott_val),
    }
    x123_vals = {
        "X1": GENRE_LABEL_TO_CODE.get(x1_label),
        "X2": GENRE_LABEL_TO_CODE.get(x2_label),
        "X3": GENRE_LABEL_TO_CODE.get(x3_label),
    }

    Xrow = build_manual_row(FEATURE_COLS, base_nums, x123_vals, onoff_selections)
    raw_pred = model.predict(Xrow.to_numpy())[0]
    pred_label = str(raw_pred)  # ëª¨ë¸ì´ ESFJ/ESTJ/INTP/INFPë¥¼ ì§ì ‘ ì£¼ëŠ” ì „ì œ

    st.success(f"ì˜ˆì¸¡ êµ°ì§‘: **{pred_label}**")
    # (ì˜µì…˜) ê¸°ì¡´ ì¹´ë“œ
    render_type_card(pred_label)
    # NEW) 4ì¶• ì¡°í•© ì„¤ëª…
    render_mbti_combo(pred_label)

    # (ì˜µì…˜) í™•ë¥  ë§‰ëŒ€
    if hasattr(model, "predict_proba"):
        try:
            probs = model.predict_proba(Xrow.to_numpy())[0]
            classes = getattr(model, "classes_", None)
            if classes is not None:
                dfp = pd.DataFrame({"class": classes, "prob": probs}).sort_values("prob", ascending=False)
                st.bar_chart(dfp.set_index("class"))
        except Exception:
            pass


